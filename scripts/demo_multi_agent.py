#!/usr/bin/env python3
"""
å¤š Agent ç®€å†ä¼˜åŒ–æ¼”ç¤ºè„šæœ¬

å±•ç¤º ContentAgent + LayoutAgent ååŒå·¥ä½œçš„æ•ˆæœã€‚
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from agents import (
    ContentAgent,
    LayoutAgent,
    ResumeAgentOrchestrator,
)


def demo_with_mock_llm():
    """ä½¿ç”¨ Mock LLM æ¼”ç¤º"""
    import json
    
    class MockLLM:
        """æ¨¡æ‹Ÿ LLM"""
        def __init__(self):
            self.call_count = 0
        
        def chat(self, prompt: str, system_prompt: str = None) -> str:
            self.call_count += 1
            
            # æ ¹æ® prompt å†…å®¹è¿”å›ä¸åŒå“åº”
            if "åˆ†æ" in prompt or "ç»´åº¦" in prompt:
                return json.dumps({
                    "analysis": {
                        "summary_score": 6,
                        "experience_score": 5,
                        "project_score": 7,
                        "skills_score": 6,
                        "overall_score": 6
                    },
                    "weaknesses": [
                        "ä¸ªäººç®€ä»‹è¿‡äºç®€çŸ­ï¼Œç¼ºä¹äº®ç‚¹",
                        "é¡¹ç›®ç»å†ç¼ºå°‘é‡åŒ–æŒ‡æ ‡",
                        "æŠ€èƒ½æè¿°ä¸å¤Ÿå…·ä½“"
                    ],
                    "opportunities": [
                        "æ·»åŠ å…·ä½“çš„é‡åŒ–æˆæœ",
                        "ä½¿ç”¨STARæ³•åˆ™é‡æ„é¡¹ç›®æè¿°",
                        "çªå‡ºæŠ€æœ¯æ·±åº¦å’Œè§£å†³çš„æŒ‘æˆ˜"
                    ],
                    "reasoning": "ç®€å†åŸºæœ¬ä¿¡æ¯å®Œæ•´ï¼Œä½†éœ€è¦åŠ å¼ºå†…å®¹çš„ä¸“ä¸šæ€§å’Œå½±å“åŠ›å±•ç¤º"
                }, ensure_ascii=False)
            
            elif "ä¼˜åŒ–" in prompt:
                return """```json
{
    "name": "é™ˆäº®æ±Ÿ",
    "title": "AI/æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ",
    "summary": "ç”µå­ç§‘æŠ€å¤§å­¦ç ”ç©¶ç”Ÿï¼Œä¸“æ³¨äºæ·±åº¦å­¦ä¹ ä¸è®¡ç®—æœºè§†è§‰é¢†åŸŸã€‚ç†Ÿç»ƒæŒæ¡ PyTorch/TensorFlow æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå…·å¤‡æ‰å®çš„ç®—æ³•åŸºç¡€å’Œå·¥ç¨‹å®è·µèƒ½åŠ›ã€‚åœ¨æ ¡æœŸé—´ä¸»å¯¼å¤šä¸ª AI é¡¹ç›®ï¼ŒåŒ…æ‹¬åŒ»å­¦å›¾åƒå¤„ç†ã€å¤§è¯­è¨€æ¨¡å‹åº”ç”¨ç­‰æ–¹å‘ã€‚",
    "education": [
        {
            "school": "ç”µå­ç§‘æŠ€å¤§å­¦",
            "degree": "ç¡•å£«ç ”ç©¶ç”Ÿ",
            "major": "ç”µå­ä¿¡æ¯",
            "start_date": "2024.09",
            "end_date": "2027.06"
        }
    ],
    "experiences": [],
    "projects": [
        {
            "name": "åŒ»å­¦å›¾åƒé‡‘å±ä¼ªå½±å»é™¤ç³»ç»Ÿ",
            "role": "é¡¹ç›®è´Ÿè´£äºº",
            "description": "åŸºäºæ·±åº¦å­¦ä¹ çš„ CT å›¾åƒé‡‘å±ä¼ªå½±æ ¡æ­£ç³»ç»Ÿ",
            "highlights": [
                "è®¾è®¡å¹¶å®ç°çº¿æ€§æ’å€¼+æ·±åº¦å­¦ä¹ çš„æ··åˆç®—æ³•ï¼Œä¼ªå½±å»é™¤ç‡è¾¾ 85%",
                "ä¼˜åŒ– Radon å˜æ¢æŠ•å½±åŸŸå¤„ç†æµç¨‹ï¼Œå¤„ç†é€Ÿåº¦æå‡ 40%",
                "æ„å»ºåŒ»å­¦å›¾åƒæ•°æ®é›† 500+ æ ·æœ¬ï¼Œè¦†ç›–å¤šç§é‡‘å±ä¼ªå½±åœºæ™¯"
            ],
            "tech_stack": ["Python", "PyTorch", "scikit-image", "NumPy"]
        },
        {
            "name": "æ™ºèƒ½ç®€å†ç”Ÿæˆ Agent",
            "role": "æ ¸å¿ƒå¼€å‘è€…",
            "description": "åŸºäº ReAct æ¶æ„çš„å¤š Agent ç®€å†ä¼˜åŒ–ç³»ç»Ÿ",
            "highlights": [
                "è®¾è®¡ ContentAgent + LayoutAgent å¤šæ™ºèƒ½ä½“åä½œæ¶æ„",
                "é›†æˆ LLM å®ç°ç®€å†å†…å®¹è‡ªåŠ¨ä¼˜åŒ–ï¼Œä¸“ä¸šåº¦è¯„åˆ†æå‡ 30%",
                "æ”¯æŒå¤šç§æ¨¡æ¿æ ·å¼ï¼Œç”Ÿæˆä¼ä¸šçº§ Word æ–‡æ¡£"
            ],
            "tech_stack": ["Python", "LangChain", "python-docx", "OpenAI API"]
        }
    ],
    "skills": [
        {"name": "Python", "level": "expert"},
        {"name": "PyTorch", "level": "proficient"},
        {"name": "TensorFlow", "level": "familiar"},
        {"name": "æ·±åº¦å­¦ä¹ ", "level": "proficient"},
        {"name": "è®¡ç®—æœºè§†è§‰", "level": "proficient"}
    ]
}
```"""
            
            elif "å¸ƒå±€" in prompt or "é…ç½®" in prompt:
                return json.dumps({
                    "section_order": ["header", "summary", "education", "projects", "skills"],
                    "style": "modern",
                    "color_scheme": "professional",
                    "font_config": {
                        "family": "Microsoft YaHei",
                        "title_size": 18,
                        "heading_size": 11,
                        "body_size": 9
                    },
                    "spacing_config": {
                        "margin": 0.5,
                        "section_gap": 8,
                        "item_gap": 3
                    },
                    "visual_elements": {
                        "use_icons": True,
                        "use_skill_bars": True,
                        "use_timeline": False,
                        "highlight_keywords": True
                    },
                    "content_limits": {
                        "compact_mode": False,
                        "max_experiences": 4,
                        "max_projects": 3,
                        "max_highlights_per_item": 4
                    },
                    "design_notes": "åº”å±Šç ”ç©¶ç”Ÿç®€å†ï¼Œæ•™è‚²å’Œé¡¹ç›®ç»å†ä¼˜å…ˆå±•ç¤ºï¼Œçªå‡ºæŠ€æœ¯èƒ½åŠ›å’Œç ”ç©¶æ½œåŠ›"
                }, ensure_ascii=False)
            
            return "{}"
    
    # åŸå§‹ç®€å†æ•°æ®
    original_resume = {
        "name": "é™ˆäº®æ±Ÿ",
        "email": "chenliangjiang@example.com",
        "phone": "138****1234",
        "summary": "ç ”ä¸€å­¦ç”Ÿ",
        "education": [
            {
                "school": "ç”µå­ç§‘æŠ€å¤§å­¦",
                "degree": "ç¡•å£«ç ”ç©¶ç”Ÿ",
                "major": "ç”µå­ä¿¡æ¯",
                "start_date": "2024.09",
                "end_date": "2027.06"
            }
        ],
        "projects": [
            {
                "name": "å›¾åƒå¤„ç†é¡¹ç›®",
                "description": "å¤„ç†åŒ»å­¦å›¾åƒ"
            }
        ],
        "skills": ["Python", "PyTorch", "æ·±åº¦å­¦ä¹ "]
    }
    
    print("=" * 60)
    print("å¤š Agent ç®€å†ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»º Mock LLM
    llm = MockLLM()
    
    # åˆ›å»ºåè°ƒå™¨
    orchestrator = ResumeAgentOrchestrator(
        llm=llm,
        enable_content_optimization=True,
        enable_layout_optimization=True,
    )
    
    print("\nğŸ“ åŸå§‹ç®€å†:")
    print(f"  å§“å: {original_resume['name']}")
    print(f"  ç®€ä»‹: {original_resume['summary']}")
    print(f"  é¡¹ç›®æ•°: {len(original_resume['projects'])}")
    
    # è¿è¡Œä¼˜åŒ–
    print("\nğŸš€ å¼€å§‹å¤š Agent ä¼˜åŒ–...")
    result = orchestrator.optimize(original_resume)
    
    print("\nğŸ“Š ä¼˜åŒ–ç»“æœ:")
    print(f"  æˆåŠŸ: {result.success}")
    print(f"  è€—æ—¶: {result.execution_time:.2f}s")
    print(f"  LLM è°ƒç”¨æ¬¡æ•°: {llm.call_count}")
    
    if result.success:
        print("\nâœ¨ ä¼˜åŒ–åçš„ç®€å†:")
        optimized = result.optimized_resume
        print(f"  å§“å: {optimized.get('name', 'N/A')}")
        print(f"  èŒä½: {optimized.get('title', 'N/A')}")
        print(f"  ç®€ä»‹: {optimized.get('summary', 'N/A')[:50]}...")
        
        projects = optimized.get('projects', [])
        print(f"  é¡¹ç›®æ•°: {len(projects)}")
        for i, proj in enumerate(projects[:2], 1):
            print(f"    {i}. {proj.get('name', 'N/A')}")
            highlights = proj.get('highlights', [])
            for h in highlights[:2]:
                print(f"       â€¢ {h[:40]}...")
        
        print("\nğŸ“ å¸ƒå±€é…ç½®:")
        layout = result.layout_config
        print(f"  ç« èŠ‚é¡ºåº: {' â†’ '.join(layout.get('section_order', []))}")
        print(f"  æ ·å¼: {layout.get('style', 'N/A')}")
        print(f"  è®¾è®¡è¯´æ˜: {layout.get('design_notes', 'N/A')}")
        
        if result.content_suggestions:
            print("\nğŸ’¡ å†…å®¹ä¼˜åŒ–å»ºè®®:")
            for s in result.content_suggestions[:3]:
                print(f"  â€¢ {s}")
    
    print("\n" + "=" * 60)
    print("æ¼”ç¤ºå®Œæˆ!")
    print("=" * 60)


def demo_single_agents():
    """æ¼”ç¤ºå•ç‹¬ä½¿ç”¨å„ Agent"""
    import json
    
    class SimpleMockLLM:
        def chat(self, prompt: str, system_prompt: str = None) -> str:
            return json.dumps({
                "analysis": {"overall_score": 7},
                "weaknesses": ["éœ€è¦é‡åŒ–æˆæœ"],
                "opportunities": ["æ·»åŠ å…·ä½“æ•°æ®"],
                "reasoning": "æ•´ä½“ä¸é”™"
            }, ensure_ascii=False)
    
    llm = SimpleMockLLM()
    
    print("\n--- ContentAgent å•ç‹¬ä½¿ç”¨ ---")
    content_agent = ContentAgent(llm)
    
    resume = {"name": "æµ‹è¯•", "summary": "å·¥ç¨‹å¸ˆ"}
    reasoning = content_agent.think(resume)
    print(f"åˆ†æç»“æœ: {reasoning[:100]}...")
    
    print("\n--- LayoutAgent å•ç‹¬ä½¿ç”¨ ---")
    layout_agent = LayoutAgent(llm)
    
    config = layout_agent._get_default_config(resume)
    print(f"é»˜è®¤é…ç½® - æ ·å¼: {config['style']}")
    print(f"é»˜è®¤é…ç½® - ç« èŠ‚é¡ºåº: {config['section_order']}")


if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("        å¤š Agent æ¶æ„æ¼”ç¤º")
    print("=" * 60)
    
    # ä½¿ç”¨ Mock LLM æ¼”ç¤ºå®Œæ•´æµç¨‹
    demo_with_mock_llm()
    
    # æ¼”ç¤ºå•ç‹¬ä½¿ç”¨å„ Agent
    demo_single_agents()

